# Rationality: From AI to Zombies

by Eliezer Yudkowsky

[Goodreads](https://www.goodreads.com/book/show/25131230-rationality)

## Quotes & notes

> P. C. Hodgell said: “That which can be destroyed by the truth should be.”

If something is not true we should destroy it. We shouldn't shun trying to destroy it. We shouldn't feel bad about trying to destroy it. If it's not true, if it's a lie, if it's false, it should be our duty to kill it. Just because we're trying to be rid of something (which is usually a negative position) we shouldn't not destroy it because of the negative perception of destruction. Seek the truth and, in doing so, you will annihilate that which is not true. By discovering the truth you prove that which is not true, false.

> “That which the truth nourishes should thrive.”

Corollary of the previous quote. But also used specifically to say "it is rational to feel". If something good happens, I feel happy, and there shouldn't be any confusion as to whether feeling 'happy' is rational.

> The outside view is when you deliberately avoid thinking about the special, unique features of this project, and
just ask how long it took to finish broadly similar projects in the past

Planning Falacy. People think they can plan :/ People naturally imagine everything going exactly as planned. No unexpected delays, no unforseen issues, always seeing the 'best case' exactly the same as the 'best guess' realistic scenario. This is proven.

There is a good debiasing heuristic to solve the planning fallacy, which is to use an "outside view" instead of an "inside view". The inside view is what we usually consider 'planning'. The where, when, how of the unique features of the task to complete. The outside view ignores everything that is unique about the project (which seems counterintuitive - the more detailed and tailored the planning, the more accurate, right?) but produces far better results.

"If you're doing something _broadly_ similar to a reference class of previous projects. Just ask how long similar projects have tkane in the past, without considering _any_ of the spcial properties of this project. You'll get back an answer that soudns hideously long, and clearly reflects no understanding of the special reasons why this particular task will take less time. This answer is true. Deal with it."

> the illusion of transparency: We always know what we mean by our words, and so we expect others to know it
too

When we communicate, all we produce are our words. But what we mean by the words we say are guided by the grand knowledge inside our heads of what we really meant. All the other party gets is our words. And they must interpret the full meaning from those words alone. 
Ambiguous sentence example: The man is chasing a woman on a bicycle

TL;DR When you say something and get frustrated that someone doesn't understand exactly what you mean, it's probably your fault! :)

Closely related to hindsight bias. Also, the curse of knowledge.

> A clear argument has to lay out an inferential pathway, starting from what the audience already knows or
accepts. If you don’t recurse far enough, you’re just talking to yourself.

In hunter-gatherer tribes, all knowledge was effectively universal. Knowledge was passed down (inherited) by speech and memory. All members of the tribe knew the same thing. Public, universal knowledge. Thus if any new knowledge occured, everyone was only _one inferential step_ away from knowing it. If you discover a new oasis, you don't need to explain what an oasis is, why it's a good idea to drink water, how to walk etc. All these concepts are known by everyone so you don't have to explain them. All you have to do is explain where the new oasis is.

In modern society, with many more concepts and disciplines, no one has universal knowledge and some concepts may be hundreds of inferential steps away from a universally shared background premise eg. Quantum physics to a layman.

If explaining a concept you must ensure you work _from_ the shared knowledge of your audience and build up the concept step by step.
